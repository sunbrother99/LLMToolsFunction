# LLMToolsFunction
å¾ˆå¥½ï¼æ—¢ç„¶ä½ ä½¿ç”¨çš„æ˜¯ **Qwen æ¨¡å‹**ï¼Œæˆ‘ä»¬å¯ä»¥å°†å·¥å…·è°ƒç”¨çš„ SFT æ•°æ®å‡†å¤‡ä¸º HuggingFace æ ¼å¼ï¼ˆä¹Ÿå¯ç§°ä¸º ChatML æˆ– Qwen çš„è®­ç»ƒå…¼å®¹æ ¼å¼ï¼‰ï¼Œå¹¶é…å¥—æä¾›ï¼š

- âœ… **æ•°æ®æ„é€ å™¨**ï¼šæ ¹æ® query å’Œå‡½æ•°å + å‚æ•°ç”Ÿæˆæ ‡å‡†æ ¼å¼
- âœ… **è®­ç»ƒæ•°æ®è¾“å‡ºä¸º JSON/JSONL**
- âœ… **HuggingFace Dataset æ ¼å¼å‡†å¤‡è„šæœ¬**
- âœ… **è®­ç»ƒ pipelineï¼ˆä½¿ç”¨ `transformers` å’Œ `Trainer`ï¼‰**

---

## ğŸ“¦ ä¸€ã€ChatML æ ¼å¼è¯´æ˜ï¼ˆQwen ä¸“ç”¨ï¼‰

Qwen å¾®è°ƒé€šå¸¸ä½¿ç”¨ç±»ä¼¼å¦‚ä¸‹æ ¼å¼çš„å¯¹è¯è®°å½•ï¼ˆæ¯æ¡æ•°æ®æ˜¯å®Œæ•´å¯¹è¯ï¼‰ï¼š

```json
{
  "input": "<|im_start|>system\nä½ æ˜¯ä¸€ä¸ªå¯ä»¥è°ƒç”¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹<|im_end|>\n<|im_start|>user\næŸ¥ä¸€ä¸‹å¹¿å·å¤©æ°”<|im_end|>\n<|im_start|>assistant\n<function_call>{\"name\": \"get_weather\", \"arguments\": {\"city\": \"å¹¿å·\"}}</function_call><|im_end|>"
}
```

Qwen é€šè¿‡ `<function_call>{...}</function_call>` æ ‡ç­¾æ ‡è¯†å‡½æ•°è°ƒç”¨ã€‚

é¢å¤–çš„
ä½¿ç”¨ SFT è®­ç»ƒçš„æ•°æ®æ ¼å¼é€šå¸¸ä¸ºï¼š

ğŸ“„ å¸¸è§æ ¼å¼ï¼šOpenAIã€ChatGLMã€Baichuanã€Qwen å‡æ”¯æŒè¿™ç§æ ¼å¼
{
  "messages": [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¯ä»¥è°ƒç”¨å†…éƒ¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹"},
    {"role": "user", "content": "å¸®æˆ‘æŸ¥ä¸€ä¸‹å¹¿å·çš„å¤©æ°”"},
    {
      "role": "assistant",
      "function_call": {
        "name": "get_weather",
        "arguments": "{ \"city\": \"å¹¿å·\" }"
      }
    }
  ]
}
æœ€ä¸Šé¢çš„qwenæ ¼å¼æ˜¯qwenæ¨¡å‹çš„ä¸“ç”¨æ ¼å¼ï¼Œå¦‚æœä»¥openaiçš„æ¥å£å½¢å¼ç»„è£…ï¼Œåˆ™æ˜¯ã€å¸¸è§æ ¼å¼ã€‘è¿™ç§ã€‚

---

## ğŸ§° äºŒã€æ•°æ®æ„é€ å™¨ï¼ˆPython è„šæœ¬ï¼‰

åˆ›å»ºä¸€ä¸ªè„šæœ¬ `generate_qwen_toolcall_dataset.py`ï¼š

```python
import json

# ä½ å¯ä»¥å®šä¹‰æ›´å¤šæ ·ä¾‹ï¼Œæˆ–ä»æ—¥å¿—æ„é€ 
examples = [
    ("æŸ¥ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”", "get_weather", {"city": "åŒ—äº¬"}),
    ("å¸®æˆ‘å®šä½ä¸Šæµ·çš„ä½ç½®", "map_lookup", {"place": "ä¸Šæµ·"}),
    ("æˆ‘æƒ³æœç´¢ä¸€ä¸‹Qwenæ¨¡å‹çš„ç”¨é€”", "search", {"query": "Qwenæ¨¡å‹çš„ç”¨é€”"}),
]

def build_chatml_entry(query, tool_name, args):
    return {
        "input": (
            "<|im_start|>system\nä½ æ˜¯ä¸€ä¸ªå¯ä»¥è°ƒç”¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹<|im_end|>\n"
            f"<|im_start|>user\n{query}<|im_end|>\n"
            f"<|im_start|>assistant\n<function_call>{{\"name\": \"{tool_name}\", \"arguments\": {json.dumps(args, ensure_ascii=False)}}}</function_call><|im_end|>"
        )
    }

def main():
    output_path = "qwen_toolcall_train.jsonl"
    with open(output_path, "w", encoding="utf-8") as f:
        for query, tool, args in examples:
            record = build_chatml_entry(query, tool, args)
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    print(f"æ•°æ®é›†å·²ç”Ÿæˆï¼š{output_path}")

if __name__ == "__main__":
    main()
```

---

## ğŸ“‚ ä¸‰ã€åŠ è½½ HuggingFace Dataset æ ¼å¼ï¼ˆç”¨äºè®­ç»ƒï¼‰

ä½¿ç”¨ `datasets` åº“å°†ç”Ÿæˆçš„ `jsonl` è½¬ä¸º HuggingFace æ ¼å¼ï¼š

```python
from datasets import load_dataset

dataset = load_dataset('json', data_files='qwen_toolcall_train.jsonl')
print(dataset['train'][0])
```

---

## ğŸ”§ å››ã€è®­ç»ƒ Pipeline è„šæœ¬ï¼ˆtransformers + Qwenï¼‰

```python
from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling
from datasets import load_dataset

model_path = "Qwen/Qwen-7B-Chat"  # æˆ–ä½ çš„æœ¬åœ°è·¯å¾„
dataset = load_dataset('json', data_files='qwen_toolcall_train.jsonl')['train']

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)

def tokenize(example):
    return tokenizer(example['input'], truncation=True, padding='max_length', max_length=1024)

tokenized_dataset = dataset.map(tokenize)

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

training_args = TrainingArguments(
    output_dir="./qwen-toolcall-checkpoints",
    evaluation_strategy="no",
    save_strategy="steps",
    save_steps=50,
    num_train_epochs=3,
    per_device_train_batch_size=2,
    logging_dir="./logs",
    logging_steps=10,
    fp16=True,
    save_total_limit=2,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator
)

trainer.train()
```

---

## âœ… è¾“å‡ºæ ·ä¾‹ï¼ˆè®­ç»ƒåæ•ˆæœé¢„æœŸï¼‰ï¼š

è¾“å…¥ç”¨æˆ·é—®å¥ï¼š
```
æŸ¥ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”
```

ç”Ÿæˆå›å¤ï¼š
```
<function_call>{"name": "get_weather", "arguments": {"city": "åŒ—äº¬"}}</function_call>
```

---

## ğŸ¯ æ€»ç»“

| æ¨¡å— | å†…å®¹ |
|------|------|
| âœ… æ•°æ®æ ¼å¼ | ChatML æ ¼å¼ï¼Œä½¿ç”¨ `<function_call>` æ ‡ç­¾ |
| âœ… æ„é€ å™¨ | æ”¯æŒä» query + å·¥å…· + å‚æ•°åˆæˆè®­ç»ƒæ ·æœ¬ |
| âœ… è®­ç»ƒ | ä½¿ç”¨ HuggingFace `Trainer` å®Œæˆå¾®è°ƒ |
| âœ… ç›®æ ‡ | æé«˜ Qwen åœ¨ function calling åœºæ™¯ä¸‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ |

---

éœ€è¦æˆ‘å¸®ä½ ï¼š
- è‡ªåŠ¨ä»æ¥å£æ—¥å¿—æ„é€ å¤§æ‰¹é‡æ•°æ®
- å°è£…ä¸º `train.py + config.yaml` å¯ä¸€é”®è®­ç»ƒå½¢å¼
- æ”¯æŒå¤šè½®è°ƒç”¨ã€å‡½æ•°åµŒå¥—ç­‰å¤æ‚åœºæ™¯

å¯ä»¥ç»§ç»­å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥å¸®ä½ è‡ªåŠ¨åŒ–æ•´ç†å’Œéƒ¨ç½²å¾®è°ƒç³»ç»Ÿã€‚æ˜¯å¦ä¹Ÿéœ€è¦éªŒè¯ä»£ç æ˜¯å¦èƒ½åœ¨ä½ ç°åœ¨çš„æœåŠ¡å™¨ç¯å¢ƒä¸‹è·‘é€šï¼Ÿ
